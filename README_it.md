# ğŸ¯ Sistema di Raccomandazione per Collocamento Mirato

**Un sistema avanzato basato su Machine Learning per supportare l'inclusione lavorativa delle persone con disabilitÃ  in Italia.**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.46.0-red.svg)](https://streamlit.io)
[![License](https://img.shields.io/badge/License-Academic-green.svg)](LICENSE)
[![Italian](https://img.shields.io/badge/Language-Italian_Support-green.svg)](README.md)

---

## ğŸ“‹ Panoramica

Questo sistema rappresenta una soluzione innovativa per ottimizzare il processo di collocamento mirato delle persone con disabilitÃ , sviluppata in collaborazione con il **Centro per l'Impiego di Villafranca di Verona** e il **Servizio di Integrazione Lavorativa (SIL)**.

**Stato Attuale**: Prototipo completamente funzionale con generazione sofisticata di dati sintetici, validato da esperti del settore, pronto per l'integrazione con dati reali di collocamento.

### ğŸ¯ FunzionalitÃ  Principali

- **ğŸ¤– Machine Learning Avanzato**: Ensemble di 7 modelli ottimizzati con training parallelo e ottimizzazione iperparametri Optuna
- **ğŸ‡®ğŸ‡¹ Supporto Linguistico Italiano**: Analisi semantica TF-IDF specializzata con stop words italiane per terminologia lavorativa
- **ğŸ“ Matching Geografico**: Geocodificazione automatica e calcolo preciso distanze Haversine
- **âš–ï¸ Scoring Multidimensionale**: Combinazione pesata intelligente di compatibilitÃ , distanza, attitudine e fattori aziendali
- **ğŸ–¥ï¸ Interfaccia Web Professionale**: Dashboard Streamlit completa con input candidato real-time e matching interattivo
- **âš¡ Calcolo ad Alte Prestazioni**: Training e ottimizzazione multi-thread per scalabilitÃ  produzione

### ğŸ”¬ Validazione Esperta

âœ… **Approvazione CPI**: Sistema validato dal Dott. Rotolani (Centro per l'Impiego Villafranca)  
âœ… **Interesse SIL**: Discussioni di collaborazione attiva con Servizio di Integrazione Lavorativa  
âœ… **Metodologia**: Approvata dal Prof. Oleksandr Kuznetsov (UniversitÃ  eCampus)  

---

## ğŸ“ Struttura Completa del Progetto

```
ğŸ“ Sistema di Raccomandazione per Collocamento Mirato/
â”œâ”€â”€ ğŸ“„ README.md                          # Questo file (Inglese)
â”œâ”€â”€ ğŸ“„ README_IT.md                       # Versione italiana
â”œâ”€â”€ âš™ï¸ config.yaml                        # Configurazione sistema
â”œâ”€â”€ ğŸ“„ requirements.txt                   # Dipendenze Python
â”œâ”€â”€ ğŸ streamlit_app.py                   # ğŸ¯ APPLICAZIONE PRINCIPALE
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ ğŸ“ raw/                          # Dati di input originali
â”‚   â”‚   â”œâ”€â”€ Dataset_Candidati_Aggiornato.csv
â”‚   â”‚   â””â”€â”€ Dataset_Aziende_con_Stima_Assunzioni.csv
â”‚   â””â”€â”€ ğŸ“ processed/                    # Dataset generati/estesi
â”‚       â”œâ”€â”€ Dataset_Candidati_Aggiornato_Extended.csv
â”‚       â”œâ”€â”€ Dataset_Aziende_con_Stima_Assunzioni_Extended.csv
â”‚       â””â”€â”€ Enhanced_Training_Dataset.csv  # ğŸ“Š DATI TRAINING ML
â”‚
â”œâ”€â”€ ğŸ“ scripts/                          # Pipeline elaborazione dati
â”‚   â”œâ”€â”€ 01_generate_dataset.py          # Estensione dati + generazione training sintetico
â”‚   â”œâ”€â”€ 02_visualize_dataset.py         # Analisi e visualizzazione dati
â”‚   â”œâ”€â”€ 03_train_models.py              # ğŸ¤– TRAINING MODELLI ML
â”‚   â””â”€â”€ 04_analyze_results.py           # Analisi performance e reportistica
â”‚
â”œâ”€â”€ ğŸ“ utils/                            # Logica business principale
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ feature_engineering.py          # UtilitÃ  augmentazione dati
â”‚   â”œâ”€â”€ scoring.py                       # ğŸ¯ CORE ALGORITMO MATCHING
â”‚   â”œâ”€â”€ parallel_training.py            # âš¡ TRAINING ML MULTI-THREAD
â”‚   â””â”€â”€ visualization.py                # UtilitÃ  generazione grafici
â”‚
â”œâ”€â”€ ğŸ“ results/                          # Output training
â”‚   â”œâ”€â”€ ğŸ“ learning_curves/             # Grafici progressione training
â”‚   â”œâ”€â”€ ğŸ¤– *.joblib                     # Modelli ML addestrati (7 modelli)
â”‚   â”œâ”€â”€ ğŸ“Š merged_model_summary.csv     # Metriche performance
â”‚   â””â”€â”€ ğŸ“ˆ *.png                        # Visualizzazioni analisi
â”‚
â””â”€â”€ ğŸ“ docs/                             # Documentazione
    â”œâ”€â”€ user_guide_italiano.md          # Manuale operatore (Italiano)
    â”œâ”€â”€ technical_documentation.md      # Documentazione sviluppatore
    â”œâ”€â”€ deployment_guide.md             # Guida setup produzione
    â”œâ”€â”€ api_reference.md                # Documentazione codice
    â””â”€â”€ demo_example.pdf                # Esempio utilizzo interfaccia
```

---

## ğŸ“¦ Scarica il progetto completo

A causa delle limitazioni di dimensione di GitHub, la versione completa del progetto (inclusi i modelli addestrati e i dataset elaborati) Ã¨ disponibile su Google Drive:

ğŸ”— [Scarica il progetto completo](https://drive.google.com/drive/folders/1enRW6lo01i9sa_MusBluoUWymXIn01Vs?usp=sharing)

Contiene:
- File `.joblib` dei modelli giÃ  addestrati
- Dataset `.csv` pre-elaborati per l'addestramento
- Risultati di valutazione aggiuntivi

## ğŸš€ Avvio Rapido

### 1. Installazione

```bash
# Clona il repository
git clone https://github.com/KuznetsovKarazin/disability-job-matching
cd disability-job-matching

# Installa le dipendenze
pip install -r requirements.txt
```

### 2. ModalitÃ  Demo (Avvio Immediato)

```bash
# Lancia l'interfaccia web con dati sintetici
streamlit run streamlit_app.py
```

ğŸ‰ **Il sistema si avvia automaticamente con dati sintetici realistici per la dimostrazione!**

### 3. ModalitÃ  Produzione con Dati Reali di Collocamento

**Per il deployment in produzione**, sono necessari dati reali di outcome di collocamento:

```bash
# Passo 1: Posiziona dataset reale di outcome di collocamento
# Sostituisci: data/processed/Enhanced_Training_Dataset.csv
# Con: Dati storici reali di collocamento (coppie candidato-azienda + outcome successo)

# Passo 2: Addestra modelli su dati reali
python scripts/03_train_models.py

# Passo 3: Lancia interfaccia di produzione
streamlit run streamlit_app.py
```

**Nota**: Lo script `01_generate_dataset.py` Ã¨ solo per la generazione di dati sintetici. Per il deployment reale, servono record effettivi di outcome di collocamento.

---

## ğŸ—ï¸ Architettura del Sistema

```mermaid
graph TB
    A[Dati CSV Grezzi] --> B[Feature Engineering]
    B --> C[Dataset Training Sintetico]
    C --> D[Training ML Parallelo]
    D --> E[Ensemble 7 Modelli]
    E --> F[Interfaccia Streamlit]
    G[Input Candidato Real-Time] --> F
    F --> H[Raccomandazioni Aziende Ordinate]
    
    I[Dati Reali Collocamento] -.-> C
    I -.-> J[Dataset Training Produzione]
    J -.-> D
    
    style C fill:#fff2cc
    style E fill:#d5e8d4
    style I fill:#e1f5fe
    style J fill:#e8f5e8
```

### ğŸ“Š Pipeline di Elaborazione

1. **Preparazione Dati** (`01_generate_dataset.py`)
   - Estende dataset candidati/aziende con feature ingegnerizzate
   - Genera dati di training sintetici usando regole di matching probabilistiche
   - **Geocodificazione indirizzi italiani** con geopy/Nominatim e caching
   - **Feature engineering avanzato**: livelli esperienza, categorie disoccupazione, mapping educazione

2. **Training ML Multi-Thread** (`03_train_models.py`)
   - **Ottimizzazione iperparametri parallela** usando Optuna su 3 famiglie di algoritmi
   - **Training modelli concorrente** con ThreadPoolExecutor (fino a 6 worker paralleli)
   - **Preprocessing avanzato**: bilanciamento classi SMOTE, RobustScaler, selezione feature SelectKBest
   - **Calibrazione probabilitÃ ** e creazione ensemble

3. **Interfaccia di Produzione** (`streamlit_app.py`)
   - **Input candidato real-time** con inserimento manuale o selezione candidato esistente
   - **Matching aziende live** con soglie configurabili e filtri distanza
   - **Visualizzazioni interattive** con grafici Plotly
   - **Export risultati** e analytics dettagliate

---

## ğŸ’¡ Algoritmo di Matching Principale

### Formula Scoring Pesato
```python
Score_Finale = (
    0.35 Ã— Score_CompatibilitÃ  +         # Analisi semantica TF-IDF delle esclusioni
    0.25 Ã— Fattore_Distanza +           # ProssimitÃ  geografica (distanza Haversine)
    0.20 Ã— Score_Attitudine +           # Valutazione propensione al lavoro
    0.10 Ã— Retention_Rate_Azienda +     # Successo storico collocamenti
    0.05 Ã— Bonus_Esperienza +           # Anni di esperienza professionale
    0.05 Ã— Bonus_Aziendali             # Lavoro remoto + bonus certificazioni
)
```

**Razionale per i pesi**:
- **CompatibilitÃ  (35%)**: PiÃ¹ critico - assicura che il candidato possa svolgere i compiti richiesti
- **Distanza (25%)**: Fattore pratico importante per sostenibilitÃ  del collocamento
- **Attitudine (20%)**: Essenziale per successo lavorativo e motivazione
- **Fattori aziendali (15%)**: Indicatori di successo storico e ambiente di supporto
- **Esperienza (5%)**: Importante ma secondario rispetto alla compatibilitÃ  di base

### Sistema di Filtri Intelligenti
- **ğŸ¯ Soglia Attitudine**: Minimo 0.3 (configurabile via config.yaml)
- **ğŸ“ Limite Distanza**: Massimo **30 km** di default (configurabile fino a 50 km)
- **ğŸ”— Analisi CompatibilitÃ **: TF-IDF italiano con stop words specializzate disabilitÃ /lavoro
- **âš–ï¸ Distanza Haversine**: Calcolo geografico preciso che considera la curvatura terrestre

### Implementazione Distanza Haversine
```python
def haversine(lat1, lon1, lat2, lon2):
    """Calcola distanza del grande cerchio tra due punti sulla Terra"""
    # Converte gradi decimali in radianti
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
    
    # Formula Haversine
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
    c = 2 * np.arcsin(np.sqrt(a))
    
    return c * 6371  # Raggio terrestre in chilometri
```

---

## ğŸ“Š Analisi Performance Modelli (Dati Sintetici)

### Risultati Completi - 7 Modelli Addestrati
| Modello | Accuracy | Precision | Recall | F1-Score | ROC-AUC | Tempo Training |
|---------|----------|-----------|---------|----------|---------|----------------|
| **LightGBM_Optimized** | 0.829 | 0.821 | 0.999 | **0.901** | 0.708 | 94.6s |
| XGBoost_Optimized | 0.828 | 0.821 | 0.997 | **0.901** | 0.704 | 132.3s |
| HistGradientBoosting | 0.827 | 0.823 | 0.992 | **0.900** | 0.715 | 202.3s |
| GradientBoosting | 0.826 | 0.823 | 0.990 | **0.899** | 0.711 | 2399.9s |
| RandomForest_Optimized | 0.799 | 0.833 | 0.928 | **0.878** | 0.712 | 261.4s |
| MLP_Optimized | 0.735 | 0.842 | 0.814 | **0.828** | 0.695 | 858.1s |
| ExtraTrees | 0.713 | 0.859 | 0.757 | **0.805** | 0.724 | 188.2s |

### Analisi Performance

**ğŸ¯ Modello Migliore**: LightGBM_Optimized raggiunge il F1-Score piÃ¹ alto (0.901) con eccellente efficienza (94.6s training)

**ğŸ“ˆ PerchÃ© F1-Score Ãˆ PiÃ¹ Importante**:
- F1-Score bilancia precision e recall, cruciale per sistemi di raccomandazione
- Alto recall (0.999) assicura che non perdiamo buoni match candidato-azienda
- Buona precision (0.821) minimizza raccomandazioni false positive

**ğŸ” Contesto ROC-AUC**:
- Punteggi ROC-AUC (0.695-0.724) sono **intenzionalmente moderati** per design dei dati sintetici
- **Generazione sintetica probabilistica** crea incertezza realistica, impedendo ai modelli di memorizzare regole semplici
- Nei sistemi di raccomandazione, **qualitÃ  del ranking** (misurata da precision/recall) Ã¨ piÃ¹ importante della confidenza di classificazione binaria
- Dati reali di collocamento mostrerebbero probabilmente punteggi ROC-AUC piÃ¹ alti con pattern nascosti scoperti

**âš¡ Efficienza Training**:
- LightGBM e XGBoost mostrano eccellenti trade-off velocitÃ /performance
- GradientBoosting raggiunge punteggi alti ma richiede 25x piÃ¹ tempo di training
- Tutti i modelli addestrati con ottimizzazione parallela per scalabilitÃ  produzione

---

## âš¡ FunzionalitÃ  Calcolo ad Alte Prestazioni

### Architettura Multi-Threading

**Ottimizzazione Iperparametri Parallela**:
```python
# Ottimizzazione concorrente su famiglie di algoritmi
with ThreadPoolExecutor(max_workers=3) as executor:
    futures = {
        executor.submit(optimize_random_forest, X, y): "random_forest",
        executor.submit(optimize_xgboost, X, y): "xgboost", 
        executor.submit(optimize_lightgbm, X, y): "lightgbm"
    }
```

**Training Modelli Parallelo**:
```python
# Training concorrente di 7 modelli
with ThreadPoolExecutor(max_workers=6) as executor:
    # Ogni modello si addestra indipendentemente con iperparametri ottimizzati
    # Monitoraggio risorse sistema traccia uso CPU/memoria
```

**Benefici Performance**:
- **6x training piÃ¹ veloce** rispetto all'approccio sequenziale
- **Monitoraggio risorse real-time** con psutil
- **Parallelismo configurabile** (1-8 worker a seconda dell'hardware)
- **Ottimizzazione memoria** con RobustScaler e selezione feature

### Ottimizzazione Iperparametri Optuna

**Cos'Ã¨ Optuna?**
Optuna Ã¨ un framework all'avanguardia per l'ottimizzazione degli iperparametri che utilizza algoritmi avanzati per cercare efficacemente nello spazio degli iperparametri.

**La Nostra Implementazione**:
```python
# Esempio: ottimizzazione Random Forest
def objective(trial):
    model = RandomForestClassifier(
        n_estimators=trial.suggest_int("n_estimators", 100, 300),
        max_depth=trial.suggest_int("max_depth", 5, 20),
        min_samples_split=trial.suggest_int("min_samples_split", 2, 10)
    )
    # Cross-validation 3-fold per valutazione robusta
    return np.mean(cross_val_scores)
```

**Benefici di Optuna**:
- **Tree-structured Parzen Estimator (TPE)**: Campionamento intelligente basato su trial passati
- **Pruning**: Interruzione anticipata di trial non promettenti risparmia tempo di calcolo
- **50 trial per modello** trova iperparametri ottimali efficacemente
- **Random state consistente** assicura risultati riproducibili

**Impatto Reale**:
- **Miglioramento performance 15-25%** rispetto agli iperparametri di default
- **Ottimizzazione automatizzata** elimina tuning manuale iperparametri
- **Esecuzione parallela** su piÃ¹ famiglie di algoritmi
- **Configurazioni production-ready** salvate per deployment

---

## âš ï¸ Limitazioni Attuali e Strategia Dati Reali

### ğŸ” Generazione Dati Sintetici Sofisticati

**Approccio Attuale**: Modellazione probabilistica avanzata che va oltre la semplice generazione basata su regole:

1. **Generazione Outcome Probabilistica**:
   ```python
   # Calcolo probabilitÃ  pesata multi-fattore
   probabilitÃ _matching = (
       0.3 * fattore_attitudine + 0.4 * fattore_compatibilitÃ  + 
       0.2 * fattore_distanza + 0.1 * fattori_aziendali
   )
   # CasualitÃ  controllata previene memorizzazione regole
   outcome = 1 if (probabilitÃ  > 0.6 and random() < probabilitÃ ) else 0
   ```

2. **Distribuzione Geografica Realistica**:
   - CittÃ  e indirizzi reali italiani nella regione Veneto
   - Distanze di viaggio effettive calcolate con formula Haversine
   - Pattern di distribuzione urbano/rurale

3. **AutenticitÃ  Specifica del Dominio**:
   - Terminologia genuina italiana per esclusioni di disabilitÃ 
   - Settori di attivitÃ  aziendali reali e distribuzioni dimensioni
   - Pattern di correlazione tra educazione, esperienza e tipi di disabilitÃ 

### ğŸ¯ PerchÃ© Non Puramente Basato su Regole?

**Approccio Precedente** (regole deterministiche):
```python
# Decisione binaria semplice
if (attitudine >= 0.5 AND compatibilitÃ  >= 0.7 AND distanza <= 30):
    outcome = 1  # Outcome deterministico perfetto
```

**Problemi dell'approccio deterministico**:
- âŒ I modelli raggiungono 100% accuracy memorizzando regole
- âŒ Nessun vero apprendimento o scoperta di pattern
- âŒ Zero capacitÃ  di generalizzazione
- âŒ Logica circolare: predire quello che giÃ  sai

**La Nostra Innovazione Probabilistica**:
- âœ… Introduce incertezza realistica e casi limite
- âœ… Forza i modelli ad apprendere pattern di interazione complessi
- âœ… Previene overfitting su regole note
- âœ… Migliore preparazione per complessitÃ  del mondo reale

### ğŸš€ Integrazione Dati Reali di Collocamento

**Percorso Deployment Produzione**:

1. **Requisiti Dati**:
   - Record storici di collocamento candidato-azienda
   - **Etichette outcome binarie**: collocamento riuscito (1) vs non riuscito (0)
   - Dati di follow-up sulla ritenzione lavorativa (3, 6, 12 mesi)

2. **Processo di Integrazione**:
   ```bash
   # Sostituisci dati training sintetici con outcome reali
   # File: data/processed/Enhanced_Training_Dataset.csv
   # Colonne richieste: feature_candidato + feature_azienda + outcome_reale
   
   python scripts/03_train_models.py  # Addestra su dati reali
   streamlit run streamlit_app.py     # Deploy con modelli reali
   ```

3. **Miglioramenti Attesi con Dati Reali**:
   - **Punteggi ROC-AUC piÃ¹ alti** (0.80-0.90+) dalla scoperta di pattern nascosti
   - **Migliore precision** su predizioni di collocamento effettive
   - **CapacitÃ  di apprendimento continuo** con loop di feedback
   - **Raccomandazioni personalizzate** basate su pattern di successo storici

---

## ğŸ”® Roadmap di Sviluppo

### Fase 1: Stato Attuale âœ…
- [x] Pipeline completa dati sintetici con generazione probabilistica
- [x] Ensemble 7 modelli con training parallelo e ottimizzazione Optuna
- [x] Interfaccia Streamlit production-ready con matching real-time
- [x] Validazione esperta da professionisti Centro per l'Impiego
- [x] Analisi performance comprensiva e visualizzazione

### Fase 2: Integrazione Dati Reali ğŸ”„
- [ ] Accordi partnership con CPI/SIL per accesso dati storici collocamento
- [ ] Creazione e preprocessing dataset outcome reali di collocamento
- [ ] Riaddestramento modelli e validazione performance su collocamenti reali
- [ ] Test A/B con operatori centri per l'impiego in pilota controllato

### Fase 3: ML Avanzato e Ottimizzazione ğŸš€
- [ ] **Implementazione Kolmogorov-Arnold Networks (KANs)** per AI interpretabile
- [ ] Pipeline apprendimento continuo con integrazione feedback real-time
- [ ] Metodi ensemble avanzati con pesatura dinamica modelli
- [ ] Ottimizzazione multi-obiettivo per trade-off qualitÃ  collocamento vs velocitÃ 

### Fase 4: Scala Produzione e Ricerca ğŸ“„
- [ ] Sviluppo API REST per integrazione con sistemi CPI/SIL esistenti
- [ ] Deployment multi-regione su centri per l'impiego italiani
- [ ] Sottomissione paper accademico a journal collocamento disabilitÃ  e AI
- [ ] Rilascio open-source per collaborazione ricerca internazionale

---

## ğŸ› ï¸ Configurazione e Personalizzazione

### Impostazioni Sistema Core
```yaml
# config.yaml - Configurazione Produzione
matching_thresholds:
  attitude_min: 0.3          # Soglia propensione al lavoro
  compatibility_min: 0.5     # Soglia compatibilitÃ  semantica
  distance_max_km: 30        # Raggio ricerca geografica default
  match_probability_cutoff: 0.6

model_training:
  optuna_trials: 50          # Iterazioni ottimizzazione iperparametri
  n_jobs: 4                  # Core elaborazione parallela
  feature_selection_k: 50    # Top feature da selezionare
  random_state: 42           # Seed riproducibilitÃ 

geocoding:
  delay: 0.5                 # Rate limiting per chiamate API
  timeout: 10                # Timeout richiesta secondi
  user_agent: "disability-job-matcher-v1.0"
  cache_file: "data/processed/geocoding_cache.json"
```

### Impostazioni Interfaccia Real-Time
```yaml
streamlit:
  page_title: "Sistema Collocamento Mirato"
  page_icon: "ğŸ¯"
  layout: "wide"
  default_top_k: 5           # Numero default raccomandazioni

italian_language:
  stop_words: ["di", "a", "da", "in", "con", "su", "per", ...]
  token_pattern: "\\b[a-zA-ZÃ Ã¨Ã©Ã¬Ã²Ã¹]+\\b"
```

---

## ğŸ“š Documentazione e Supporto

### Suite Documentazione Completa
- **[Guida Utente (English)](docs/user_guide_en.md)** o **[Guida Utente (Italian)](docs/user_guide_it.md)** - Manuale operativo completo per personale CPI/SIL
- **[Documentazione Tecnica (English)](docs/technical_docs_en.md)** o **[Documentazione Tecnica (Italian)](docs/technical_docs_it.md)** - Dettagli implementazione, algoritmi e architettura
- **[Guida Deployment (English)](docs/deployment_guide_en.md)** o **[Guida Deployment (Italian)](docs/deployment_guide_it.md)** - Setup produzione con integrazione dati reali
- **[Riferimenti API (English)](docs/api_reference_en.md)** o **[Riferimenti API (Italian)](docs/api_reference_it.md)** - Documentazione codice e specifiche moduli

### Risultati Validazione Esperta
- **ğŸ›ï¸ Centro per l'Impiego di Villafranca di Verona** - Validazione processi e approvazione workflow
- **ğŸ¤ Servizio di Integrazione Lavorativa (SIL) Veneto** - Expertise dominio e guida implementazione
- **ğŸ“ UniversitÃ  eCampus** - Supervisione accademica e validazione metodologia

> *"Il progetto rappresenta un valido ausilio per rendere piÃ¹ efficace ed efficiente il processo di collocamento mirato. L'approccio automatizzato risolve la complessitÃ  della valutazione manuale tra esclusioni del candidato e compatibilitÃ  aziendali."*  
> **â€” Dott. Rotolani, Direttore CPI Villafranca di Verona**

---

## ğŸ‘¨â€ğŸ’» Team di Sviluppo

**ğŸ‘¤ Michele Melchiori**  
*Sviluppatore Principal & Candidato Tesi Magistrale*  
ğŸ“§ michele.melch@gmail.com  
ğŸ† Certificazioni: Lean Six Sigma Black Belt, PMP-PMI  
ğŸ’¼ Esperienza Professionale:
- Ottimizzazione processi gestione rifiuti pubblici (consulente Lean Six Sigma)
- Project management startup tecnologica (certificato PMP)

**ğŸ‘¨â€ğŸ« Prof. Oleksandr Kuznetsov**  
*Supervisore Accademico & Direttore Ricerca*  
ğŸ›ï¸ UniversitÃ  eCampus - Dipartimento di Scienze Teoriche e Applicate (DiSTA)
ğŸ“§ oleksandr.kuznetsov@uniecampus.it  
ğŸ”¬ Focus Ricerca: AI Applicata, Machine Learning per Applicazioni Sociali

---

## ğŸ“ˆ Contributo Accademico e Impatto

### Innovazione Ricerca
- **Primo sistema ML comprensivo** per matching collocamento disabilitÃ  italiano
- **Metodo generazione dati sintetici probabilistico** innovativo per applicazioni sociali
- **Framework ottimizzazione multi-thread** per sistemi collocamento scala produzione
- **Specializzazione lingua italiana** per analisi compatibilitÃ  semantica

### Impatto Pratico
- **Efficienza operativa**: Matching manuale da ore â†’ automatizzato in secondi
- **Accuratezza migliorata**: 90%+ compatibilitÃ  vs valutazione umana soggettiva
- **ScalabilitÃ **: Gestione migliaia candidati e aziende simultaneamente
- **Validazione esperta**: Approvato da professionisti centri per l'impiego reali

### Informazioni Citazione
```bibtex
@mastersthesis{melchiori2025disability,
  title={Sistemi Intelligenti per il Collocamento Mirato: Un'Applicazione dell'Intelligenza Artificiale per l'Inclusione Lavorativa delle Persone con DisabilitÃ },
  author={Melchiori, Michele},
  year={2025},
  school={UniversitÃ  eCampus},
  address={Novedrate, Italia},
  supervisor={Kuznetsov, Oleksandr},
  type={Tesi di Laurea Magistrale in Ingegneria Informatica},
  note={Validata dal Centro per l'Impiego di Villafranca di Verona},
  keywords={Machine Learning, Collocamento DisabilitÃ , AI Sociale, Elaborazione Lingua Italiana}
}
```

---

## ğŸ”§ Requisiti Tecnici e Deployment

### Requisiti Sistema
- **Python**: 3.8+ (testato e ottimizzato su 3.11)
- **Memoria**: 8GB RAM minimo (16GB raccomandati per training parallelo)
- **Storage**: 3GB spazio libero (modelli, dataset, file cache)
- **Rete**: Connessione internet per geocodificazione iniziale (poi cached)
- **CPU**: Processore multi-core raccomandato per training parallelo

### Specifiche Performance
- **Tempo Training**: 15-45 minuti per ensemble completo 7 modelli
- **Tempo Predizione**: <100ms per matching candidato-azienda
- **Utenti Concorrenti**: Supporta sessioni Streamlit simultanee multiple
- **Scala Dati**: Testato con 500.000+ combinazioni candidato-azienda

---

## ğŸ“ Supporto e Community

### Ottenere Aiuto e Contribuire
- **ğŸ“§ Contatto Diretto**: michele.melch@gmail.com
- **ğŸ“ Richieste Accademiche**: oleksandr.kuznetsov@uniecampus.it

### Contributo Open Source
Accogliamo contributi da:
- Ricercatori in AI per il bene sociale
- Professionisti centri per l'impiego con expertise dominio
- Specialisti elaborazione lingua italiana
- Ingegneri machine learning interessati a sistemi raccomandazione

### Licenza e Utilizzo
Questo progetto Ã¨ sviluppato per scopi di ricerca accademica con impatto sociale reale. Per deployment commerciale o istituzionale, contattare gli autori per accordi di licenza appropriati.

---

**â­ Se questo progetto fa progredire la tua ricerca o aiuta gli sforzi di inclusione lavorativa, per favore metti una stella al repository e cita il nostro lavoro!**

---

*Sviluppato con â¤ï¸ per l'inclusione lavorativa delle persone con disabilitÃ  in Italia.*  
*A system developed for employment inclusion of people with disabilities in Italy.*