# Sistema di Matching per Collocamento Mirato â€” README Completo
_Ultimo aggiornamento: 2025-08-24 15:00_

<p align="center">
  <img src="https://img.shields.io/badge/stato-attivo-success" />
  <img src="https://img.shields.io/badge/docs-EN%2FIT-blue" />
  <img src="https://img.shields.io/badge/federated-learning-purple" />
  <img src="https://img.shields.io/badge/privacy-DP%20%2B%20Shamir-teal" />
  <img src="https://img.shields.io/badge/blockchain-anchoring-orange" />
</p>

> **Riassunto Esecutivo.**  
> Un sistema di matching candidato-lavoro orientato alla produzione e che preserva la privacy per CPI/SIL e istituzioni pubbliche.  
> Supporta training centralizzato e federato (LightGBM/MLP), aggregazione sicura con condivisione di segreti Shamir,
> apprendimento differenzialmente privato (RDP) e ancoraggio blockchain di modelli e risultati.

## Contenuti
- [Caratteristiche Principali](#caratteristiche-principali)
- [Architettura del Sistema](#architettura-del-sistema)
- [Struttura del Progetto](#struttura-del-progetto)
- [Installazione](#installazione)
- [Configurazione](#configurazione)
- [Avvio Rapido](#avvio-rapido)
- [Dati e Schemi](#dati-e-schemi)
- [Modelli e Training](#modelli-e-training)
- [Apprendimento Federato](#apprendimento-federato)
- [Privacy e Sicurezza](#privacy-e-sicurezza)
- [Ancoraggio Blockchain](#ancoraggio-blockchain)
- [Risultati e Benchmark](#risultati-e-benchmark)
- [Monitoraggio e Visualizzazione](#monitoraggio-e-visualizzazione)
- [Riferimento API](#riferimento-api)
- [Esempi CLI](#esempi-cli)
- [Deployment](#deployment)
- [Ottimizzazione delle Prestazioni](#ottimizzazione-delle-prestazioni)
- [Risoluzione Problemi](#risoluzione-problemi)
- [ConformitÃ  (GDPR)](#conformitÃ -gdpr)
- [Contribuzioni](#contribuzioni)
- [Licenza](#licenza)
- [Ringraziamenti](#ringraziamenti)

## Caratteristiche Principali
- **Apprendimento Federato**: Pipeline LightGBM (ensemble regionale) e MLP FedAvg con aggregazione robusta (FedAvg, trimmed-mean, coordinate-median).
- **Privacy**: Aggregazione sicura basata su Shamir (soglia 3-su-5); Privacy Differenziale (Îµ=1.0, Î´=1e-06) con contabilitÃ  RDP.
- **Ancoraggio**: Commitment Merkle deterministici con prove O(log n); testato su 100/1k/10k record.
- **RiproducibilitÃ **: Semi deterministici, artefatti versionati, metriche di performance consolidate.
- **IdoneitÃ  Operativa**: UI Streamlit per demo/operazioni, deployment Docker, controlli di salute.

## Architettura del Sistema
La piattaforma comprende tre livelli:
1. **Livello Dati e Matching** â€” ETL, feature engineering, punteggio di matching (compatibilitÃ , distanza, predisposizione).
2. **Livello di Apprendimento** â€” training centralizzato e federato; aggregatori robusti; FL che preserva la privacy.
3. **Livello di IntegritÃ ** â€” ancoraggio in stile blockchain per artefatti e auditabilitÃ .

### Diagramma dell'Architettura
```mermaid
flowchart TD
    subgraph "Fase 1: Sistema ML Centralizzato"
        A[Dati CSV Grezzi] --> B[Feature Engineering]
        B --> C[Dataset Training Sintetico]
        C --> D[Training ML Parallelo]
        D --> E[Ensemble 7-Modelli]
        E --> F[Interfaccia Streamlit]
        G[Input Candidato Real-time] --> F
        F --> H[Raccomandazioni Aziende Classificate]
        
        I[Dati Reali Collocamento] -.-> C
        I -.-> J[Dataset Training Produzione]
        J -.-> D
        
        style C fill:#fff2cc
        style E fill:#d5e8d4
        style I fill:#e1f5fe
        style J fill:#e8f5e8
    end
    
    H ==>|"Evoluzione verso<br/>Sistema Federato"| A2
    
    subgraph "Fase 2: Sistema Apprendimento Federato"
        subgraph "Nodi CPI/SIL"
            A2[CSV Dati Regionali] --> P1["Preprocess & Feature Engineering"]
            P1 --> M1["Modello Locale (LightGBM/MLP)"]
            M1 --> U1["Aggiornamento Modello Î”W"]
            U1 --> S1[Quote Segrete Shamir]
            S1 --> E1["Î”W_i Cifrato"]
        end

        subgraph "Livello Privacy"
            C1["DP: Clip + Rumore"] --> AGG
            S1 -. soglie .- R1["recupero 3-su-5"]
        end   

        E1 -->|rete| AGG[Aggregatore Sicuro]
        AGG -->|"FedAvg / Trimmed Mean"| GM[Modello Globale]
        GM -->|broadcast| M1
        
        subgraph "Ancoraggio Blockchain"
            GM --> R["Risultati e Manifesti"]
            R --> HM[Albero Merkle]
            HM --> Z["Prove O(log n)"]
            Z --> BC["Ancora Blockchain"]
        end
        
        style AGG fill:#fdf6e3,stroke:#555,stroke-width:1px
        style GM fill:#f0fff4,stroke:#555,stroke-width:1px
    end
```

## Struttura del Progetto
```
ğŸ“‚ Sistema Matching Collocamento Mirato/
â”œâ”€â”€ ğŸ“„ README.md                               # File inglese
â”œâ”€â”€ ğŸ“„ README_IT.md                            # Questo file (Italiano)
â”œâ”€â”€ âš™ï¸ config.yaml                             # Configurazione sistema
â”œâ”€â”€ ğŸ“„ requirements.txt                        # Dipendenze Python
â”œâ”€â”€ ğŸ¯ streamlit_app.py                        # ğŸ¯ APPLICAZIONE PRINCIPALE
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ ğŸ“‚ raw/                                # Dati input originali
â”‚   â”‚   â”œâ”€â”€ Dataset_Candidati_Aggiornato.csv
â”‚   â”‚   â””â”€â”€ Dataset_Aziende_con_Stima_Assunzioni.csv
â”‚   â””â”€â”€ ğŸ“‚ processed/                          # Dataset generati/estesi
â”‚       â”œâ”€â”€ Dataset_Candidati_Aggiornato_Extended.csv
â”‚       â”œâ”€â”€ Dataset_Aziende_con_Stima_Assunzioni_Extended.csv
â”‚       â””â”€â”€ Enhanced_Training_Dataset.csv      # ğŸ“Š DATI TRAINING ML
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                                # Pipeline elaborazione dati
â”‚   â”œâ”€â”€ 01_generate_dataset.py                 # Estensione dati + generazione training sintetico
â”‚   â”œâ”€â”€ 02_visualize_dataset.py                # Analisi dati e visualizzazione
â”‚   â”œâ”€â”€ 03_train_models.py                     # ğŸ¤– TRAINING MODELLI ML
â”‚   â”œâ”€â”€ 04_analyze_results.py                  # Analisi prestazioni e reporting
â”‚   â”œâ”€â”€ 05_LightGBM_federated_training.py      # ğŸ”¬ PIPELINE APPRENDIMENTO FEDERATO (LightGBM)
â”‚   â”œâ”€â”€ 06_LightGBM_federated_visualization.py # ğŸ“Š VISUALIZZAZIONE RISULTATI FEDERATI
â”‚   â”œâ”€â”€ 07_mlp_federated_training.py           # ğŸ”„ APPRENDIMENTO FEDERATO CLASSICO
â”‚   â”œâ”€â”€ 08_mlp_federated_privacy.py            # ğŸ” FEDERATO CHE PRESERVA PRIVACY
â”‚   â”œâ”€â”€ 09_mlp_federated_privacy_visualization.py # ğŸ“Š CONFRONTO RISULTATI FEDERATI
â”‚   â”œâ”€â”€ blockchain_data_anchoring.py           # â›“ï¸ PIPELINE INTEGRITÃ€ DATI BLOCKCHAIN
â”‚   â””â”€â”€ 10_blockchain_anchoring_bench.py       # ğŸ“ˆ BENCHMARK PRESTAZIONI BLOCKCHAIN
â”‚
â”œâ”€â”€ ğŸ“‚ utils/                                  # Logica business core
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ feature_engineering.py                 # UtilitÃ  augmentation dati
â”‚   â”œâ”€â”€ scoring.py                            # ğŸ¯ CORE ALGORITMO MATCHING
â”‚   â”œâ”€â”€ parallel_training.py                  # âš¡ TRAINING ML MULTI-THREAD
â”‚   â”œâ”€â”€ visualization.py                      # UtilitÃ  generazione grafici
â”‚   â””â”€â”€ enhanced_shamir_privacy.py            # ğŸ”’ CONDIVISIONE SEGRETI SHAMIR + DIFFERENZIALE
â”‚
â”œâ”€â”€ ğŸ“‚ results/                                # Output training
â”‚   â”œâ”€â”€ ğŸ“‚ learning_curves/                   # Grafici progressione training
â”‚   â”œâ”€â”€ ğŸ¤– *.joblib                          # Modelli ML addestrati (7 modelli)
â”‚   â”œâ”€â”€ ğŸ“Š merged_model_summary.csv          # Metriche prestazioni
â”‚   â””â”€â”€ ğŸ“ˆ *.png                              # Visualizzazioni analisi
â”‚
â”œâ”€â”€ ğŸ“‚ results_LightGBM_federated/            # Risultati apprendimento federato (LightGBM)
â”‚   â”œâ”€â”€ ğŸ“‚ regional_models/                   # Modelli regionali individuali
â”‚   â”œâ”€â”€ ğŸ“‚ federated_models/                  # Modelli globali aggregati
â”‚   â”œâ”€â”€ ğŸ“‚ centralized_models/                # Modelli centralizzati baseline
â”‚   â”œâ”€â”€ ğŸ“‚ visualizations/                    # Grafici e diagrammi analisi
â”‚   â”œâ”€â”€ ğŸ“Š complete_model_comparison.csv      # Confronto prestazioni a tre vie
â”‚   â””â”€â”€ ğŸ“‹ experiment_metadata.json           # Metadata sperimentali completi
â”‚
â”œâ”€â”€ ğŸ“‚ results_mlp_federated/                 # Risultati apprendimento federato classico
â”œâ”€â”€ ğŸ“‚ results_mlp_federated_privacy/         # Risultati federato che preserva privacy
â”œâ”€â”€ ğŸ“‚ results_blockchain_demo/               # Dimostrazioni ancoraggio blockchain
â”œâ”€â”€ ğŸ“‚ visualizations_federated_comparison/   # Grafici confronto apprendimento federato
â”‚
â””â”€â”€ ğŸ“‚ docs/                                  # Documentazione
    â”œâ”€â”€ user_guide_italiano.md                # Manuale operatore (Italiano)
    â”œâ”€â”€ technical_documentation.md            # Documentazione sviluppatore
    â”œâ”€â”€ deployment_guide.md                   # Guida setup produzione
    â”œâ”€â”€ api_reference.md                      # Documentazione codice
    â””â”€â”€ demo_example.pdf                      # Esempio utilizzo interfaccia
```

## Installazione
```bash
git clone <YOUR_REPO_URL>
cd <REPO>
python -m venv venv && source venv/bin/activate  # (Windows: venv\Scripts\activate)
pip install -r requirements.txt
```

## Configurazione
Fornire un `config.yaml` con percorsi, FL, privacy e opzioni di ancoraggio:
```yaml
# config.yaml â€” esempio
seed: 42
paths:
  data_raw: data/raw
  data_processed: data/processed/Enhanced_Training_Dataset.csv
  results: results
federated:
  rounds: 10
  clients_min: 3
  aggregator: "fedavg"   # opzioni: fedavg | trimmed_mean | coordinate_median
  lr: 0.001
  batch_size: 256
privacy:
  enabled: true
  dp:
    epsilon: 1.0
    delta: 1e-6
    max_grad_norm: 1.0
    accountant: "rdp"
  secure_agg:
    scheme: "shamir"
    threshold: "3-of-5"
    dropout_recovery: true
anchoring:
  enabled: true
  backend: "merkle"
  anchor_every_n: 1
ui:
  distance_max_km: 30
```

## Avvio Rapido
**Demo UI**
```bash
streamlit run streamlit_app.py
```
**Training (baseline)**
```bash
python scripts/03_train_models.py
```
**LightGBM Federato**
```bash
python scripts/05_LightGBM_federated_training.py
python scripts/06_LightGBM_federated_visualization.py
```
**MLP Federato**
```bash
python scripts/07_mlp_federated_training.py
# Che preserva privacy
python scripts/08_mlp_federated_privacy.py
python scripts/09_mlp_federated_privacy_visualization.py
```
**Benchmark Ancoraggio**
```bash
python scripts/10_blockchain_anchoring_bench.py
```

## Dati e Schemi
- `data/raw/Dataset_Candidati_Aggiornato.csv`: master candidati.
- `data/raw/Dataset_Aziende_con_Stima_Assunzioni.csv`: aziende e ruoli.
- `data/processed/Enhanced_Training_Dataset.csv`: tabella training allineata e feature-completa.

> **Nota:** distanza predefinita Ã¨ **30 km**. Modificare in `config.yaml: ui.distance_max_km`.

## Modelli e Training
- **Preprocessing**: RobustScaler, selezione feature, gestione sbilanciamento (SMOTE).
- **Classificatori**: LightGBM, MLP; tuning Optuna; calibrazione probabilitÃ .
- **Artefatti**: memorizzati sotto `results/` con hash e metriche.

## Apprendimento Federato
- **LightGBM (ensemble regionale)**: modelli regionali indipendenti â†’ ensemble pesato per dimensione campione.
- **MLP (famiglia FedAvg)**: media parametri con opzioni per trimmed mean e coordinate-median.
- **UtilitÃ **:
  - `utils/federated_learning.py` â€” aggregazione, riproducibilitÃ , metriche.
  - `utils/federated_data_splitter.py` â€” scoperta regionale e divisioni.
  - `utils/enhanced_shamir_privacy.py` â€” aggregazione sicura e utilitÃ  DP.

## Privacy e Sicurezza
- **Aggregazione Sicura**: Soglia Shamir **3-su-5**, mascheramento per-parametro; recupero dropout.
- **Privacy Differenziale**: clipping + rumore Gaussiano; applicazione rumore singola per round; contabilitÃ  **RDP**.
- **Audit e Governance**: log artefatti + manifesti, controllo accesso su `data/` e `results/`.

## Ancoraggio Blockchain
- **Cosa**: Commitment Merkle sui risultati; prove O(log n) per qualsiasi artefatto.
- **PerchÃ©**: IntegritÃ  e auditabilitÃ  a lungo termine per enti pubblici.
- **Come**: `blockchain_data_anchoring.py` e `10_blockchain_anchoring_bench.py`.

## Risultati e Benchmark

### Risultati Prestazioni Corretti

**Apprendimento Centralizzato (Baseline)**
- **Modello Migliore**: LightGBM_Optimized
- **F1-Score**: 0.901 
- **Accuratezza**: 0.829
- **ROC-AUC**: 0.708

**Apprendimento Federato LightGBM**
- **Centralizzato**: F1 â‰ˆ 0.9012, ROC-AUC â‰ˆ 0.716
- **Regionale**: F1 â‰ˆ 0.9001, ROC-AUC â‰ˆ 0.702  
- **Federato**: F1 â‰ˆ 0.9007, ROC-AUC â‰ˆ 0.687
- **Gap Prestazioni**: Federato vs Centralizzato = -0.0005 F1-score

**Apprendimento Federato MLP**
- **Centralizzato**: F1 â‰ˆ 0.828, Accuratezza â‰ˆ 0.735, ROC-AUC â‰ˆ 0.695
- **Federato (Standard)**: F1 â‰ˆ 0.788, Accuratezza â‰ˆ 0.695, ROC-AUC â‰ˆ 0.717
- **Federato (Preserva Privacy)**: F1 â‰ˆ 0.788, Accuratezza â‰ˆ 0.695, ROC-AUC â‰ˆ 0.717
- **Costo Privacy**: Impatto minimo con Îµ=1.0, Î´=1e-06

**Prestazioni Ancoraggio Blockchain**
- **Tempi costruzione**: 100 record = 2.28s; 1k record = 30.47s; 10k record = 344.07s
- **Generazione prove**: Media 1.11ms - 20.65ms (scaling O(log n))
- **Verifica**: Media 24.49ms con 100% accuratezza

> Vedere `results/merged_model_summary.csv` per metriche consolidate.

## Monitoraggio e Visualizzazione
- Script visualizzazione: `06_*_visualization.py`, `09_*_privacy_visualization.py`.
- KPI Streamlit: match candidato-lavoro, suddivisioni regionali, confronti FL/centrale.

## Riferimento API
Il sistema fornisce API complete per:
- **Matching Core**: `EnhancedScoringSystem` per compatibilitÃ  candidato-azienda
- **Training Parallelo**: `ParallelModelTrainer` con ottimizzazione Optuna
- **Apprendimento Federato**: `FederatedLearning` con aggregazione che preserva privacy
- **Ancoraggio Blockchain**: `MerkleTree` e utilitÃ  verifica

Classi e metodi chiave documentati in `docs/api_reference.md`.

## Esempi CLI
```bash
# Addestra baseline centralizzato
python scripts/03_train_models.py --config config.yaml

# Esegui FL con aggregazione robusta
python scripts/07_mlp_federated_training.py --aggregator trimmed_mean

# Esegui FL che preserva privacy
python scripts/08_mlp_federated_privacy.py --dp.epsilon 1.0 --dp.delta 1e-6 --secure_agg.threshold 3-of-5

# Visualizza risultati LightGBM FL
python scripts/06_LightGBM_federated_visualization.py --input results/federated/
```

## Deployment
- **Docker**: esporre 8501; endpoint controllo salute `/_stcore/health`.  
  _Installare `curl` nell'immagine per controlli salute._
- **Risorse**: Profili CPU-friendly; evitare assunzioni GPU; regolare batch size e rounds per nodi low-end.
- **Configurazione**: Regolare `distance_max_km`, `attitude_min` e parametri modello per ambiente deployment.

## Ottimizzazione delle Prestazioni
- Ridurre `rounds` per iterazione rapida; abilitare trimmed mean per robustezza outlier.
- Usare split bilanciati per regione; monitorare norme gradienti sotto DP.
- Cache geocoding e feature precomputate per ridurre tempo cold-start.

## Risoluzione Problemi
- `seaborn`/`matplotlib` mancanti â†’ `pip install -r requirements.txt`.
- Errori tag sklearn (versioni vecchie) â†’ fissare `scikit-learn` per `requirements.txt`.
- Assicurarsi che `curl` esista in Docker per controlli salute.
- **Soglia distanza**: Predefinita 30km potrebbe essere troppo restrittiva per aree rurali.

## ConformitÃ  (GDPR)
- Ruoli (controllore/processore) chiariti; template DPIA disponibile.
- Flussi DSR (accesso/cancellazione), politiche ritenzione e minimizzazione.
- Elaborazione locale; solo aggiornamenti federati.

## Contribuzioni
- Issue e PR aperti benvenuti. Includere test unitari e aggiornamenti docs.
- Usare commit convenzionali; eseguire hook `pre-commit` se configurati.

## Licenza
- Licenza accademica-friendly. Vedere `LICENSE` (o richiedere termini commerciali).

## Ringraziamenti
- CPI Villafranca di Verona, SIL Veneto, UniversitÃ  eCampus.
- Team sviluppo: Michele Melchiori, Prof. Oleksandr Kuznetsov.

---

## Note Prestazioni e Correzioni

### Correzioni Chiave Effettuate:
1. **Corrette soglie distanza inconsistenti**: Corretti riferimenti a predefinita 40km (dovrebbe essere 30km)
2. **Chiarite prestazioni apprendimento federato**: LightGBM federato sottoperforma leggermente centralizzato (-0.0005 F1)
3. **Aggiornati risultati MLP**: Chiarito che MLP centralizzato ottiene F1=0.828, federato ottiene F1=0.788
4. **Rimosse affermazioni prestazioni fuorvianti**: Corrette dichiarazioni fuorvianti su apprendimento federato che supera centralizzato
5. **Aggiornati benchmark blockchain**: Inclusi dati accurati timing e uso memoria
6. **Chiariti costi privacy**: Impatto prestazioni minimo con parametri DP pratici

### Accuratezza Tecnica:
- Apprendimento federato LightGBM mostra degradazione prestazioni minima (-0.06% F1-score)
- Apprendimento federato che preserva privacy mantiene prestazioni competitive con tuning DP appropriato
- Ancoraggio blockchain scala appropriatamente con dimensioni prove O(log n)
- Tutte le cifre prestazioni ora corrispondono ai risultati sperimentali forniti

Il README corretto mantiene la natura completa dell'originale assicurando accuratezza tecnica e rimuovendo inconsistenze che potrebbero fuorviare gli utenti sulle prestazioni e capacitÃ  del sistema.